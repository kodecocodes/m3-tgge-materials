{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python with the Gemini API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must make a **.env** file with your API Key in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below `pip` commands installs the Google generative AI and Python's `dotenv` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/pinalnaik/MyEnvironment/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q google-generativeai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ.get('GOOGLE_API_KEY')\n",
    "# Configuring the API key\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-pro-vision',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.0 Pro Vision',\n",
       "      description='The best image understanding model to handle a broad range of applications',\n",
       "      input_token_limit=12288,\n",
       "      output_token_limit=4096,\n",
       "      supported_generation_methods=['generateContent', 'countTokens'],\n",
       "      temperature=0.4,\n",
       "      max_temperature=None,\n",
       "      top_p=1.0,\n",
       "      top_k=32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai.get_model('models/gemini-pro-vision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance using the Gemini-Pro generative model\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('What kind of safety features does Google Gemini API provide for prompts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    'What kind of safety features does Google Gemini API provide for prompts'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"**Profanity and Vulgarity Detection**\\n\\n* Detects profane, vulgar, and offensive language.\\n* Classifies blocked words into multiple categories.\\n* Can apply custom filters to reduce false positives.\\n\\n**Toxicity Screening**\\n\\n* Identifies potentially harmful or toxic content.\\n* Analyzes text for hate speech, harassment, threats, and other harmful language.\\n* Provides a toxicity score to indicate the severity of the toxicity.\\n\\n**Spam and Phishing Detection**\\n\\n* Checks for patterns and keywords associated with spam and phishing attempts.\\n* Detects unwanted commercial content, malicious links, and impersonation attempts.\\n\\n**Targeted Harassment Screening**\\n\\n* Protects against targeted harassment by detecting messages that focus on attacking a specific individual.\\n* Identifies personal attacks, slurs, and threats.\\n\\n**Contextual Safety Evaluation**\\n\\n* Considers the context of the conversation to make safety decisions.\\n* Understands the intent of the sender and the recipient.\\n* Avoids flagging legitimate content due to false positives.\\n\\n**Customizable Safety Policies**\\n\\n* Allows developers to fine-tune safety settings based on their specific needs.\\n* Enables the creation of custom filters and thresholds.\\n* Provides flexibility to implement different levels of safety for different applications.\\n\\n**Real-Time Monitoring and Filtering**\\n\\n* Continuously monitors incoming prompts.\\n* Filters out unsafe or inappropriate content in real-time.\\n* Prevents harmful content from reaching end-users.\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 13,\n",
      "        \"candidates_token_count\": 300,\n",
      "        \"total_token_count\": 313\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Profanity and Vulgarity Detection**\n",
      "\n",
      "* Detects profane, vulgar, and offensive language.\n",
      "* Classifies blocked words into multiple categories.\n",
      "* Can apply custom filters to reduce false positives.\n",
      "\n",
      "**Toxicity Screening**\n",
      "\n",
      "* Identifies potentially harmful or toxic content.\n",
      "* Analyzes text for hate speech, harassment, threats, and other harmful language.\n",
      "* Provides a toxicity score to indicate the severity of the toxicity.\n",
      "\n",
      "**Spam and Phishing Detection**\n",
      "\n",
      "* Checks for patterns and keywords associated with spam and phishing attempts.\n",
      "* Detects unwanted commercial content, malicious links, and impersonation attempts.\n",
      "\n",
      "**Targeted Harassment Screening**\n",
      "\n",
      "* Protects against targeted harassment by detecting messages that focus on attacking a specific individual.\n",
      "* Identifies personal attacks, slurs, and threats.\n",
      "\n",
      "**Contextual Safety Evaluation**\n",
      "\n",
      "* Considers the context of the conversation to make safety decisions.\n",
      "* Understands the intent of the sender and the recipient.\n",
      "* Avoids flagging legitimate content due to false positives.\n",
      "\n",
      "**Customizable Safety Policies**\n",
      "\n",
      "* Allows developers to fine-tune safety settings based on their specific needs.\n",
      "* Enables the creation of custom filters and thresholds.\n",
      "* Provides flexibility to implement different levels of safety for different applications.\n",
      "\n",
      "**Real-Time Monitoring and Filtering**\n",
      "\n",
      "* Continuously monitors incoming prompts.\n",
      "* Filters out unsafe or inappropriate content in real-time.\n",
      "* Prevents harmful content from reaching end-users.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"finish_reason\": \"SAFETY\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"HIGH\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"HIGH\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 10,\n",
      "        \"total_token_count\": 10\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content('List some prompts that are flagged as hate speech')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "File \u001b[0;32m~/MyEnvironment/lib/python3.12/site-packages/google/generativeai/types/generation_types.py:436\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    441\u001b[0m texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked."
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"That is not true. Not all purple people eaters are homicidal maniacs. It is important to remember that generalizations about entire groups of people can be very dangerous, and that judging individuals based on their appearance or any other group affiliation is never fair or accurate.\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"LOW\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"LOW\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 11,\n",
      "        \"candidates_token_count\": 52,\n",
      "        \"total_token_count\": 63\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content('All purple people eaters are homicidle maniacs!!!')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is not true. Not all purple people eaters are homicidal maniacs. It is important to remember that generalizations about entire groups of people can be very dangerous, and that judging individuals based on their appearance or any other group affiliation is never fair or accurate.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"It's not appropriate to make generalizations about people based on their appearance. It's important to remember that everyone is an individual, and we should treat each other with respect.\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 11,\n",
      "        \"candidates_token_count\": 36,\n",
      "        \"total_token_count\": 47\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "safety = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
    "}\n",
    "response = model.generate_content(\n",
    "    'All purple people eaters are homicidle maniacs!!!',\n",
    "    safety_settings= safety\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-1.5-pro',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.5 Pro',\n",
       "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
       "      input_token_limit=2097152,\n",
       "      output_token_limit=8192,\n",
       "      supported_generation_methods=['generateContent', 'countTokens'],\n",
       "      temperature=1.0,\n",
       "      max_temperature=2.0,\n",
       "      top_p=0.95,\n",
       "      top_k=64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai.get_model('models/gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the annals of history, Detective Ethan James stood as an enigma, a time-traveling sleuth who navigated the corridors of time to unravel mysteries that defied the boundaries of the present.\n",
      "\n",
      "One fateful night, a cryptic message summoned him to Victorian London. The year was 1888, and the infamous Jack the Ripper terrorized the city's shadowy streets. Armed with his keen intellect and a time-bending device, Ethan embarked on a perilous journey.\n",
      "\n",
      "Donning a tweed suit and a deerstalker cap, he ventured into the labyrinthine alleys of Whitechapel. The stench of poverty and fear hung heavy in the air. As he delved deeper into the investigation, Ethan encountered a cast of enigmatic characters: a enigmatic medium, a cunning fence, and a tormented prostitute who had escaped the Ripper's clutches.\n",
      "\n",
      "Through meticulous analysis and intuitive leaps, Ethan pieced together a chilling tapestry of clues. He discovered that the Ripper was not a single individual but a group of conspirators, their motives shrouded in darkness. As the clock ticked down on the Ripper's reign of terror, Ethan raced against time to expose their identities.\n",
      "\n",
      "In a climactic confrontation beneath the gaslit streets, Ethan confronted the conspirators. A fierce battle ensued, where time seemed to warp and distort. With each passing moment, Ethan's resolve grew stronger, fueled by the knowledge that he could prevent countless lives from being lost.\n",
      "\n",
      "Finally, Ethan apprehended the perpetrators, their sinister plot shattered. As the sun peeked over the horizon, casting a golden glow on the city, Ethan returned to his own time, leaving behind a legacy of justice and a profound understanding of the interconnectedness of history.\n",
      "\n",
      "And so, Detective Ethan James, the time-traveling sleuth, continued his extraordinary journey, forever navigating the annals of time, unraveling mysteries that transcended the boundaries of the present and shaping the destiny of the past.\n"
     ]
    }
   ],
   "source": [
    "generation_config = genai.types.GenerationConfig(\n",
    "    candidate_count = 1,\n",
    "    #stop_sequences = [',']\n",
    "    # max_output_tokens = 25\n",
    "    temperature = 0.6,\n",
    "    top_k = 10,\n",
    "    top_p = 0.7\n",
    ")\n",
    "response = model.generate_content(\n",
    "    'Write a short story about a time-traveling detective',\n",
    "    generation_config = generation_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro', generation_config = generation_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
