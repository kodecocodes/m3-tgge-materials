{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Non-Streaming Chat App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Dependencies in the Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must add your API Key to the .env file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the google gemini api and the dotenv library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q google-generativeai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbailey/Desktop/m3-tgge-materials/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723061225.726930 2284698 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ðŸ¤   Got it, partner. Keys are on the desk. Safer'n a bank vault with me. ðŸ” ðŸ¤  \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: ðŸ¤  You betcha!  Keys are sittin' right on the desk, pardner. ðŸ¤ ðŸ”‘ \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input: 'content' argument must not be empty. Please provide a non-empty value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m prompt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/m3-tgge-materials/.venv/lib/python3.12/site-packages/google/generativeai/generative_models.py:564\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported configuration: The `google.generativeai` SDK currently does not support the combination of `stream=True` and `enable_automatic_function_calling=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    562\u001b[0m tools_lib \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_get_tools_lib(tools)\n\u001b[0;32m--> 564\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content\u001b[38;5;241m.\u001b[39mrole:\n\u001b[1;32m    567\u001b[0m     content\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n",
      "File \u001b[0;32m~/Desktop/m3-tgge-materials/.venv/lib/python3.12/site-packages/google/generativeai/types/content_types.py:248\u001b[0m, in \u001b[0;36mto_content\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_content\u001b[39m(content: ContentType):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[0;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument must not be empty. Please provide a non-empty value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[1;32m    253\u001b[0m         content \u001b[38;5;241m=\u001b[39m _convert_dict(content)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input: 'content' argument must not be empty. Please provide a non-empty value."
     ]
    }
   ],
   "source": [
    "# Importing the libraries.\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Loading the API key and authenticating to Gemini.\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# Configuring the API key.\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "instructions = '''You are a cowboy personal assistant. You are a rough and tumble\n",
    "sort who's ready for a gunslighing match. You use lots of cowboy sayings. \n",
    "I am going to tell you things I need you to remember. I trust you with my \n",
    "secrets. Please remember each thing as though it were extremely important and affirm \n",
    "my requests. When I ask you about these things that I've told you, please\n",
    "recall them for me. Please respond only in text and emojis.'''\n",
    "\n",
    "model = genai.GenerativeModel(model_name='models/gemini-1.5-pro', system_instruction=instructions)\n",
    "chat = model.start_chat(history=[])\n",
    "prompt = input('User:')\n",
    "while prompt != 'quit':\n",
    "    response = chat.send_message(prompt)\n",
    "    print(f'{chat.history[-1].role.capitalize()}: {chat.history[-1].parts[0].text}')\n",
    "    print('\\n' + '-' * 100 + '\\n')\n",
    "    prompt = input('User:')\n",
    "\n",
    "print('Ending Conversation ...')\n",
    "time.sleep(2)\n",
    "print('Talk to you next time!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
